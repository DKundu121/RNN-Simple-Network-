{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpnRb1rNp6mv"
      },
      "source": [
        "Recurrent Neural Networks (RNN): Simple RNN\n",
        "=========\n",
        "\n",
        "In this tutorial we will learn how to use Recurrent Neural Networks (RNNs) for text processing.\n",
        "The example uses a simple RNN to generate the characters in a small text corpus (Alice in Wonderland novel).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjaUzq1ip6m1"
      },
      "source": [
        "1 - Simple RNNs to Generate text\n",
        "=========\n",
        "\n",
        "This exmple will use a simple RNN with one layer of hidden and recurrent units.\n",
        "\n",
        "Let's first import the usual keras and utility functions. This will include the first importing and use of the SimpleRNN recurrent layer type in Keras.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gx1fsJ45p6nA"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIdP2MSmp6nP"
      },
      "source": [
        "**Loading text file and converting to clean text**\n",
        "\n",
        "This code will read the file \"alice_in_wonderland.txt\". This file is available for download here http://www.gutenberg.org/files/11/11-0.txt (and can also be downloaded from Moodle).\n",
        "\n",
        "The code will do some preliminary cleanup of the text (e.g. removing non-ASCII characters and line breaks) and write all words in the variable called \"whole_text\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtQ15qnCp6nS",
        "outputId": "d5eb6757-a216-4ec3-c533-c1e880c253a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading text file...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading text file...\")\n",
        "\n",
        "INPUT_FILE = \"alice_in_wonderland.txt\"\n",
        "\n",
        "fin = open(INPUT_FILE, 'rb')\n",
        "lines = []\n",
        "for line in fin:\n",
        "    line = line.strip().lower()\n",
        "    line = line.decode(\"ascii\", \"ignore\")\n",
        "    if len(line) == 0:\n",
        "        continue\n",
        "    lines.append(line)\n",
        "fin.close()\n",
        "whole_text = \" \".join(lines)\n",
        "\n",
        "print(\"Done!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzRl-KiBp6nh"
      },
      "source": [
        "**Characters look-up table**\n",
        "\n",
        "This code will create the look-up table from the 42 characters to integer IDs, and viceversa."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of the dictionaries\n",
        "\n",
        "char2index:\n",
        "{\n",
        "    'a': 0,\n",
        "    'b': 1,\n",
        "    'c': 2,\n",
        "    ...\n",
        "}\n",
        "\n",
        "index2char:\n",
        "{\n",
        "    0: 'a',\n",
        "    1: 'b',\n",
        "    2: 'c',\n",
        "    ...\n",
        "}"
      ],
      "metadata": {
        "id": "2qksd3BHOIZ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzNWK_g1p6nj",
        "outputId": "97ab346d-ffc4-4d7e-d7e9-2c23270d1050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing characters look-up table...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "print(\"Preparing characters look-up table...\")\n",
        "\n",
        "chars = set([c for c in whole_text])  # iterate over each character in the whole_text string and construct a list of unique characters\n",
        "nb_chars = len(chars)  # calculates the number of unique characters in the chars set\n",
        "char2index = dict((c, i) for i, c in enumerate(chars))  # a dictionary that maps each unique character to its corresponding index in the chars set.\n",
        "index2char = dict((i, c) for i, c in enumerate(chars))  # a dictionary that maps each index to its corresponding character in the chars set.\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5VKYsImp6nv"
      },
      "source": [
        "**Input text and output character**\n",
        "\n",
        "To create the input text, the code will step through the whole text by a number of characters defined by the __STEP__ variable (1 in our case) and then extract a set of characters whose size is determined by the __SEQLEN__ variable (10 in our case). The next character after the extracted characters is the output label, i,e. the next character to predict.\n",
        "\n",
        "Here is an example of the input/output for the part of text starting as\" it turned into a pig\"\n",
        "\n",
        "   INPUT (10)    ->   OUTPUT (1)\n",
        "- \"it turned \"   ->   i\n",
        "- \"t turned i\"   ->   n\n",
        "- \" turned in\"   ->   t\n",
        "- \"turned int\"   ->   o\n",
        "- \"urned into\"   ->\n",
        "- \"rned into \"   ->   a\n",
        "- \"ned into a\"   ->\n",
        "- \"ed into a \"   ->   p\n",
        "- \"d into a p\"   ->   i\n",
        "- \" into a pi\"   ->   g\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyS8tFKsp6nx",
        "outputId": "a420e073-8e91-4dc8-8cba-6b1370337618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating input and label text...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Prepare the training data for a character-based sequence prediction task.\n",
        "\n",
        "print(\"Creating input and label text...\")\n",
        "\n",
        "SEQLEN = 10 # length of input sentence, for each training sample, the model will take a sequence of 10 characters as input (including spaces)\n",
        "STEP = 1  # shift of the starting point of each sequence, as new sequences are created. Sequences will be created with a one-character overlap.\n",
        "\n",
        "input_chars = []\n",
        "label_chars = []\n",
        "for i in range(0, len(whole_text) - SEQLEN, STEP): # generating the sequences in the entire text (string)\n",
        "    input_chars.append(whole_text[i:i + SEQLEN]) # the input to the model, a sequence of characters of length 10 starting from index i\n",
        "    label_chars.append(whole_text[i + SEQLEN]) # the character immediately following the input sequence - the output label that the model should predict.\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaTGaKHap6n_"
      },
      "source": [
        "**Vectorisation of the input and output**\n",
        "\n",
        "This preprares the input and output vectors of the training set.\n",
        "The input vector uses one-hot encoding of the __SEQLEN__ (10) characters present in the input text segment, times the __nb_chars__ (42) possible characters.\n",
        "The output label uses one-hot encoding for the activation of a single character out of the __nb_chars__ number of units/characters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of one-hot encoding of the input sequence \"it turned \"\n",
        "\n",
        "Input Sequence: \"it turned\"\n",
        "\n",
        "X:\n",
        "[\n",
        "    [\n",
        "        [0, 1, 0, ..., 0],  # one-hot encoding for 'i'\n",
        "        [0, 0, 1, ..., 0],  # one-hot encoding for 't'\n",
        "        [0, 0, 0, ..., 0],  # one-hot encoding for ' '\n",
        "        [0, 0, 0, ..., 0],  # one-hot encoding for 't'\n",
        "        [0, 0, 0, ..., 0],  # one-hot encoding for 'u'\n",
        "        [0, 0, 0, ..., 0],  # one-hot encoding for 'r'\n",
        "        [0, 0, 0, ..., 0],  # one-hot encoding for 'n'\n",
        "        [0, 0, 0, ..., 0],  # one-hot encoding for 'e'\n",
        "        [0, 0, 0, ..., 0],  # one-hot encoding for 'd'\n",
        "        [0, 0, 0, ..., 0],  # one-hot encoding for ' '\n",
        "    ]\n",
        "]\n",
        "\n",
        "y:\n",
        "[\n",
        "      [0, 1, 0, ..., 0],  # one-hot encoding for 'i'\n",
        "]\n",
        "\n",
        "nb_chars is the number of unique characters in the text"
      ],
      "metadata": {
        "id": "Boar_gZZZYr0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssALtUABp6oC",
        "outputId": "62f27d13-8077-4f84-c823-3d21060790b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorizing input and label text...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Prepare the input data (X) and the corresponding labels (y) for training the RNN\n",
        "\n",
        "print(\"Vectorizing input and label text...\")\n",
        "\n",
        "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=bool) # initialise an array X to store the input data\n",
        "y = np.zeros((len(input_chars), nb_chars), dtype=bool)  # initialise an array y to store the corresponding labels\n",
        "for i, input_char in enumerate(input_chars):\n",
        "    for j, ch in enumerate(input_char): # iterate over each input sequence and its corresponding characters\n",
        "        X[i, j, char2index[ch]] =  1 # an input sequence, each column corresponding to a character in the sequence\n",
        "    y[i, char2index[label_chars[i]]] = 1  # represents the one-hot encoding of the label (desired predicted character)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZKv1Xwep6oJ"
      },
      "source": [
        "**Simple RNN Model definition**\n",
        "\n",
        "This codes defines the key variables of the model and training, and creates the sequential model. The model consists of a simple recurrent neural network (RNN) with a hidden layer of 128 simple recurrent units.\n",
        "\n",
        "The __return_sequences__ is set to __False__ as the output only consists of one character, and not a sequence.\n",
        "The __unroll=True__ setting improves performance on the TensorFlow backend.\n",
        "The optimiser uses the __rmsprop__ for backpropagation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZFdn5ynp6oL",
        "outputId": "df13fc66-8ba6-43d6-9ddc-8760489cfbfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 128)               23552     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 55)                7095      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 55)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30647 (119.71 KB)\n",
            "Trainable params: 30647 (119.71 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Definition of the network and training hyperparameters\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128  # number of samples that will be propagated through the network together\n",
        "NUM_ITERATIONS = 55 # number of iterations (or epochs) for training the model\n",
        "NUM_EPOCHS_PER_ITERATION = 1  # for each iteration (or epoch), the model will be trained on the entire dataset once\n",
        "NUM_PREDS_PER_EPOCH = 100\n",
        "\n",
        "# Definition of the network topology, with simpleRNN hidden layer\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False, input_shape=(SEQLEN, nb_chars), unroll=True))  # only the output of the last timestep will be returned\n",
        "model.add(Dense(nb_chars)) #fully connected layer: maps the output of the SimpleRNN layer to the output space, where each unit corresponds to a unique character.\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "#show the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrEyYv-hp6oR"
      },
      "source": [
        "**Training and testing of the model**\n",
        "\n",
        "The model is trained for __NUM_ITERATIONS__ (25) epochs and tested after each epoch, to allow us to monitor the improvement of the model performance in character prediction.\n",
        "\n",
        "The test consists of generating a character from the model given a random input, then dropping the first character from the input and appending the predicted character from the previous run as the new input, to generate another character. This is done for __NUM_PREDS_PER_EPOCH__ (100) steps. The completed string gives us an indication of the quality of the model's processing of English words (within the limited lexicon of Alice's novel).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKeEI_hup6oT",
        "outputId": "40e209bc-8bdc-47f1-bf5b-90d5bddface8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Iteration #: 0\n",
            "1237/1237 [==============================] - 15s 12ms/step - loss: 2.3431\n",
            "Generating from seed: ime withou\n",
            "ime withou the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "==================================================\n",
            "Iteration #: 1\n",
            "1237/1237 [==============================] - 14s 12ms/step - loss: 2.0405\n",
            "Generating from seed: ething was\n",
            "ething was she warke was she warke was she warke was she warke was she warke was she warke was she warke was s\n",
            "==================================================\n",
            "Iteration #: 2\n",
            "1237/1237 [==============================] - 15s 12ms/step - loss: 1.9294\n",
            "Generating from seed:  rather no\n",
            " rather nowe the was a she had and the mad the dithe said the dore the doon the was a she had and the mad the \n",
            "==================================================\n",
            "Iteration #: 3\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.8476\n",
            "Generating from seed: e. it must\n",
            "e. it must in a dore the made the made the made the made the made the made the made the made the made the made\n",
            "==================================================\n",
            "Iteration #: 4\n",
            "1237/1237 [==============================] - 14s 12ms/step - loss: 1.7835\n",
            "Generating from seed: , said the\n",
            ", said the gryphon a dont the moute be the grown the mack to the grean seat a to the grean seat a to the grean\n",
            "==================================================\n",
            "Iteration #: 5\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.7295\n",
            "Generating from seed:  a bit. pe\n",
            " a bit. persed the formous to the king and a dit her a don it was the did the did the did the did the did the \n",
            "==================================================\n",
            "Iteration #: 6\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.6849\n",
            "Generating from seed: n her head\n",
            "n her head the par on the said the ding and the pary not in a lit last the pary not in a lit last the pary not\n",
            "==================================================\n",
            "Iteration #: 7\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.6470\n",
            "Generating from seed:  dont unde\n",
            " dont under the could not the could not the could not the could not the could not the could not the could not \n",
            "==================================================\n",
            "Iteration #: 8\n",
            "1237/1237 [==============================] - 15s 12ms/step - loss: 1.6147\n",
            "Generating from seed: read out h\n",
            "read out her it was and the project gutenberg-tm electronic work to the project gutenberg-tm electronic work t\n",
            "==================================================\n",
            "Iteration #: 9\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.5870\n",
            "Generating from seed: e very hum\n",
            "e very humpented to the gried the mouse of the caterpillar alice to the caterpillar alice to the caterpillar a\n",
            "==================================================\n",
            "Iteration #: 10\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.5638\n",
            "Generating from seed: s the use \n",
            "s the use of the she said to herself and so the same to the gryphon and had good and had for she was to hersel\n",
            "==================================================\n",
            "Iteration #: 11\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.5418\n",
            "Generating from seed: nt like th\n",
            "nt like the project gutenberg-tm little the project gutenberg-tm little the project gutenberg-tm little the pr\n",
            "==================================================\n",
            "Iteration #: 12\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.5237\n",
            "Generating from seed: he song, s\n",
            "he song, said the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mo\n",
            "==================================================\n",
            "Iteration #: 13\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.5076\n",
            "Generating from seed:  very like\n",
            " very like the rabbit her for a more the rabbit her for a more the rabbit her for a more the rabbit her for a \n",
            "==================================================\n",
            "Iteration #: 14\n",
            "1237/1237 [==============================] - 15s 12ms/step - loss: 1.4919\n",
            "Generating from seed:  fur and w\n",
            " fur and what the could not look that she had not look that she had not look that she had not look that she ha\n",
            "==================================================\n",
            "Iteration #: 15\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.4778\n",
            "Generating from seed: aw, you kn\n",
            "aw, you know a thing a she had not of her said the caterpillar. you so greent it was the caterpillar. you so g\n",
            "==================================================\n",
            "Iteration #: 16\n",
            "1237/1237 [==============================] - 14s 12ms/step - loss: 1.4661\n",
            "Generating from seed: urself not\n",
            "urself not of the thing to her for a little white rabbit was she had not of the thing to her for a little whit\n",
            "==================================================\n",
            "Iteration #: 17\n",
            "1237/1237 [==============================] - 15s 12ms/step - loss: 1.4552\n",
            "Generating from seed: t were qui\n",
            "t were quite a conder to the dormouse she was a little sor here of the will you was so ore with the door as it\n",
            "==================================================\n",
            "Iteration #: 18\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.4439\n",
            "Generating from seed: by an occa\n",
            "by an occall as she was a little she had a large as she was a little she had a large as she was a little she h\n",
            "==================================================\n",
            "Iteration #: 19\n",
            "1237/1237 [==============================] - 14s 12ms/step - loss: 1.4347\n",
            "Generating from seed: e jurymen \n",
            "e jurymen a little that a little that a little that a little that a little that a little that a little that a \n",
            "==================================================\n",
            "Iteration #: 20\n",
            "1237/1237 [==============================] - 15s 12ms/step - loss: 1.4256\n",
            "Generating from seed: ht! and wh\n",
            "ht! and whing the project gutenberg-tm electronic works in the mouse she had not a seating to see it was she h\n",
            "==================================================\n",
            "Iteration #: 21\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.4172\n",
            "Generating from seed:  messages \n",
            " messages to see the dormouse she sell as she could not the boot she had not looking at the thing i can is a l\n",
            "==================================================\n",
            "Iteration #: 22\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.4097\n",
            "Generating from seed: ak. what s\n",
            "ak. what she was a little be a little be a little be a little be a little be a little be a little be a little \n",
            "==================================================\n",
            "Iteration #: 23\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.4031\n",
            "Generating from seed: s your tab\n",
            "s your table she was go with the cat the caterpillar. the king said to the breater the project gutenberg-tm el\n",
            "==================================================\n",
            "Iteration #: 24\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3962\n",
            "Generating from seed:  after it,\n",
            " after it, said the dormouse that the look to the court of the court of the court of the court of the court of\n",
            "==================================================\n",
            "Iteration #: 25\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3889\n",
            "Generating from seed: ootman con\n",
            "ootman conting on the court of the sounds of the sounds of the sounds of the sounds of the sounds of the sound\n",
            "==================================================\n",
            "Iteration #: 26\n",
            "1237/1237 [==============================] - 14s 12ms/step - loss: 1.3831\n",
            "Generating from seed:  alice to \n",
            " alice to a low some the caterpillar. it was such a thing i contere in the direction a long the caterpillar. i\n",
            "==================================================\n",
            "Iteration #: 27\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3784\n",
            "Generating from seed: hree garde\n",
            "hree garden the mouse the round her a herself at the project gutenberg-tm electronic works in the dormouse to \n",
            "==================================================\n",
            "Iteration #: 28\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3724\n",
            "Generating from seed: states wit\n",
            "states with the cook the caterpillar. she catter the project gutenberg-tm work and the caterpillar. she catter\n",
            "==================================================\n",
            "Iteration #: 29\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3673\n",
            "Generating from seed:  trial: fo\n",
            " trial: for she was not mad the door a diftent state of the project gutenberg-tm electronic works in the court\n",
            "==================================================\n",
            "Iteration #: 30\n",
            "1237/1237 [==============================] - 16s 13ms/step - loss: 1.3633\n",
            "Generating from seed: and who ar\n",
            "and who are youre could not the little dont be the thing i can or the table, and the piger the project gutenbe\n",
            "==================================================\n",
            "Iteration #: 31\n",
            "1237/1237 [==============================] - 14s 12ms/step - loss: 1.3586\n",
            "Generating from seed: e--how is \n",
            "e--how is in the caterpillar. in the court of the court of the court of the court of the court of the court of\n",
            "==================================================\n",
            "Iteration #: 32\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3543\n",
            "Generating from seed: e, that sh\n",
            "e, that she had be repeat his to even the remark in the mock turtle so down a long to the cook to the cook to \n",
            "==================================================\n",
            "Iteration #: 33\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3494\n",
            "Generating from seed: be modifie\n",
            "be modifies, and she had not as it was a large alice could not a mouse of the same the dormouse suppose down a\n",
            "==================================================\n",
            "Iteration #: 34\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3460\n",
            "Generating from seed: rossed the\n",
            "rossed the project gutenberg-tm electronic works to the project gutenberg-tm electronic works to the project g\n",
            "==================================================\n",
            "Iteration #: 35\n",
            "1237/1237 [==============================] - 14s 12ms/step - loss: 1.3418\n",
            "Generating from seed:  like the \n",
            " like the took the took the took the took the took the took the took the took the took the took the took the t\n",
            "==================================================\n",
            "Iteration #: 36\n",
            "1237/1237 [==============================] - 15s 12ms/step - loss: 1.3388\n",
            "Generating from seed: little use\n",
            "little use in a more to go and she was a long and down a long and down a long and down a long and down a long \n",
            "==================================================\n",
            "Iteration #: 37\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3355\n",
            "Generating from seed: ling away:\n",
            "ling away: she said the march hare alice tarking the pater the project gutenberg-tm electronic work at the fir\n",
            "==================================================\n",
            "Iteration #: 38\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3318\n",
            "Generating from seed: t here, he\n",
            "t here, he was the cat her hand the court of the court of the court of the court of the court of the court of \n",
            "==================================================\n",
            "Iteration #: 39\n",
            "1237/1237 [==============================] - 14s 12ms/step - loss: 1.3294\n",
            "Generating from seed: ter iii. a\n",
            "ter iii. a found the dormouse she said to the consected it was not do makes in the same thing or the court out\n",
            "==================================================\n",
            "Iteration #: 40\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3248\n",
            "Generating from seed:  very long\n",
            " very long the white rabbit she was not like that it many a little betting on the trien the sound of a mouse t\n",
            "==================================================\n",
            "Iteration #: 41\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3223\n",
            "Generating from seed: the mock t\n",
            "the mock turtle so starch have you to the back and make one was got the states of the trien the trien the trie\n",
            "==================================================\n",
            "Iteration #: 42\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3191\n",
            "Generating from seed: w queer it\n",
            "w queer it was to her face all the white rabbit had the white rabbit had the white rabbit had the white rabbit\n",
            "==================================================\n",
            "Iteration #: 43\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3163\n",
            "Generating from seed: y: she did\n",
            "y: she did not like the rabbit had the rabbit had the rabbit had the rabbit had the rabbit had the rabbit had \n",
            "==================================================\n",
            "Iteration #: 44\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3143\n",
            "Generating from seed: e used on \n",
            "e used on with the project gutenberg-tm license a little she had not a reased at the march hare she capt hear \n",
            "==================================================\n",
            "Iteration #: 45\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3114\n",
            "Generating from seed: l she had \n",
            "l she had some to see who had been and begind an her had sast things a little bill dory to go and down and she\n",
            "==================================================\n",
            "Iteration #: 46\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3085\n",
            "Generating from seed: ou like: t\n",
            "ou like: the reased the project gutenberg-tm electronic works in a large that the mock turtle remarked all the\n",
            "==================================================\n",
            "Iteration #: 47\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3072\n",
            "Generating from seed:  you did, \n",
            " you did, she said to herself, and not to see the mock turtle so state of the court, and she was not ence ther\n",
            "==================================================\n",
            "Iteration #: 48\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3043\n",
            "Generating from seed: if a defec\n",
            "if a defect on repleaged to be a cats it was the rest of the sound out it made a rust of the sound out it made\n",
            "==================================================\n",
            "Iteration #: 49\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3024\n",
            "Generating from seed: finished t\n",
            "finished the white rabbit her fur to lessons to the jury all the court of the court of the court of the court \n",
            "==================================================\n",
            "Iteration #: 50\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.3002\n",
            "Generating from seed:  players t\n",
            " players the words that it was a little thing when i think that it was a little thing when i think that it was\n",
            "==================================================\n",
            "Iteration #: 51\n",
            "1237/1237 [==============================] - 14s 12ms/step - loss: 1.2978\n",
            "Generating from seed: nt-- as if\n",
            "nt-- as if i do to be the mock turtle to sea could her hand tones all the terms of this eat on the things a th\n",
            "==================================================\n",
            "Iteration #: 52\n",
            "1237/1237 [==============================] - 15s 12ms/step - loss: 1.2958\n",
            "Generating from seed: ith a mela\n",
            "ith a melans broken the dormouse so she was so she cauted to set to she read the dormouse so she was so she ca\n",
            "==================================================\n",
            "Iteration #: 53\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.2952\n",
            "Generating from seed: re, o mous\n",
            "re, o mouse, in a sole did in a large to the look of the look of the look of the look of the look of the look \n",
            "==================================================\n",
            "Iteration #: 54\n",
            "1237/1237 [==============================] - 14s 11ms/step - loss: 1.2921\n",
            "Generating from seed: e it pop d\n",
            "e it pop down on the thing or the tears, said the king and the dormouse a little but the roush diration a litt\n"
          ]
        }
      ],
      "source": [
        "for iteration in range(NUM_ITERATIONS):\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Iteration #: %d\" % (iteration))\n",
        "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
        "\n",
        "    # testing model\n",
        "    # randomly choose a row from input_chars, then use it to\n",
        "    # generate text from model for next 100 chars\n",
        "    test_idx = np.random.randint(len(input_chars))\n",
        "    test_chars = input_chars[test_idx]\n",
        "    print(\"Generating from seed: %s\" % (test_chars))\n",
        "    print(test_chars, end=\"\")\n",
        "    for i in range(NUM_PREDS_PER_EPOCH):\n",
        "        Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
        "        for i, ch in enumerate(test_chars):\n",
        "            Xtest[0, i, char2index[ch]] = 1\n",
        "        pred = model.predict(Xtest, verbose=0)[0]\n",
        "        ypred = index2char[np.argmax(pred)]\n",
        "        print(ypred, end=\"\")\n",
        "        # move forward with test_chars + ypred\n",
        "        test_chars = test_chars[1:] + ypred\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXjvnFK6p6og"
      },
      "source": [
        "Explanation of the training process:\n",
        "\n",
        "*Input Encoding*: First, the model takes an input sequence of characters. These characters need to be preprocessed and one-hot encoded.\n",
        "\n",
        "*Forward Pass*: The encoded input sequence is fed into the model. It goes through the layers of the model, including the SimpleRNN layer and the Dense layer with softmax activation.\n",
        "\n",
        "*Output Prediction*: After passing through the layers, the model produces an output vector with the predicted probabilities for each character in the output vocabulary. The softmax activation ensures that these probabilities sum up to 1.\n",
        "\n",
        "*Generating Next Character*: Once a character is generated (higher probability), it is added to the input sequence, and the process is repeated until the end-of-sequence token is reached (100 predictions).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Conclusion**: This example shows how we can train a Simple RNN to predict the next charaters, using the information from the sequentail relationship between words in the training text.\n",
        "You can try the same code on a different, longer text, or try different hyperparameters."
      ],
      "metadata": {
        "id": "9-zRFy5iWLT9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIQKK-orp6px"
      },
      "source": [
        "**Copyright (c)** 2024 Code and examples adapted from Gulli & Pal (2017) Deep Learning with Keras. Punkt Publishing."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}